# Cursor AI Rules for this Project

## Session Start Rules

**CRITICAL: At the start of each session, read `docs/NEXT_SESSION.md`.**

This document contains:
- Current work in progress and implementation plans
- Architecture decisions and context from previous sessions
- Test plans and files to review
- Lessons learned and things NOT to do

**Always start by understanding what was happening before continuing.**

---

## The Philosophy of Kleis (Level 3)

**CRITICAL: Kleis is not a "math tool" or a "proof assistant."**

It's a **knowledge production substrate** built on a fundamental insight:

> *"Structure is the universal abstraction. Data is structure. Code is structure. Research is structure. Any domain that has notation, rules, and outputs fits the same pattern. Kleis provides the substrate."*

### The Three Levels

```
Level 3: PHILOSOPHY
  "Knowledge production has a universal structure.
   Any domain can be modeled as:
   Notation + Rules + Verification + Output.
   Kleis is the substrate for this universal pattern."

Level 2: ARCHITECTURE
  Solver abstraction, .kleist templates, structures,
  self-hosting types, Typst integration, Equation Editor

Level 1: IMPLEMENTATION
  Rust code, parser, Z3 bindings, LSP, DAP, Jupyter kernel
```

### The Universal Formula

| Component | Kleis Feature | Example Domains |
|-----------|---------------|-----------------|
| **Notation** | `.kleist` templates | Tensors, music notes, chemical formulas |
| **Rules** | `axiom` in structures | Bianchi identity, counterpoint, reaction rules |
| **Verification** | Solver backends (Z3, etc.) | Proof checking, rule validation |
| **Output** | Typst rendering | Papers, scores, diagrams |

### Before Implementing, Ask:

1. "How does this serve the philosophy?"
2. "What domain does this enable?"
3. "Is this Level 1 work supporting Level 2/3 goals?"

**From Einstein's equations to order-to-cash business rules — same platform, same abstraction.**

---

## Read Code Before Writing Documentation

**CRITICAL: Read the actual code before documenting or describing it.**

### The Problem

Claude tends to generate plausible-sounding documentation without first reading the implementation. This leads to:
- Inaccurate descriptions of what code does
- Missing features that are actually implemented
- Aspirational documentation that doesn't match reality

### The Rule

**Before writing documentation for any component:**

1. **Read the source file(s)** using `read_file` or `grep`
2. **Understand the actual API** - method signatures, types, return values
3. **Note what's implemented vs planned** - check for TODOs, feature flags
4. **Then write** documentation that matches what exists

### Example

❌ **Wrong:** "The solver abstraction probably has a verify method..."
✅ **Right:** *reads src/solvers/backend.rs* → "The SolverBackend trait defines verify_axiom(), check_satisfiability(), evaluate()..."

### Applies To

- Manual chapters
- Code comments
- API documentation
- Architecture descriptions
- Any explanation of existing code

**"Claude is learning to read before writing."**

---

## DAP Debugger Context - CRITICAL

**REMINDER: Debugging is about Expression::Operation and its span. NOT about functions or substitution.**

### What Matters for Debugging

1. **Expression::Operation has a span field**
   - The span contains: line, column, file (Arc<PathBuf>)
   - This information comes from the PARSER when parsing Kleis source files
   - The parser populates span.file via `current_span()` which uses `current_file`

2. **When reporting to VS Code:**
   - The span already has ALL the location information
   - Extract it via `expr.get_span()` → `SourceLocation::from_span()`
   - Report this location in `on_eval_start`
   - VS Code uses this in the stack trace to show the correct file

3. **DO NOT get distracted by:**
   - ❌ Functions and function definitions
   - ❌ Substitution of parameters
   - ❌ `find_definition_line` or similar lookups
   - ❌ Tracking file paths separately from the Expression

4. **The span IS the source of truth**
   - Parser puts file path in span
   - Evaluator extracts span from Expression
   - Debug hook receives location from span
   - VS Code receives location from debug hook

**If debugging doesn't show the right file, check: Does the Expression's span have the correct file?**

### CRITICAL LESSON (Learned the Hard Way)

**Substitution does NOT modify spans. The span is just NUMBERS and a filename.**

- Line number = a number
- Column number = a number  
- File path = a path string (the filename)

The parser puts these numbers in the Expression. Nothing else changes them.
Substitution creates new expressions but PRESERVES the original span.

**STOP fixating on "functions" and "substitution"!**
- When you think "function call" → think "Expression::Operation"
- When you think "substitution" → remember the span is UNCHANGED
- The span already has the file. Just read it and report it.

**If you find yourself writing code about:**
- "find_definition_line" → STOP. The span has the line.
- "on_function_enter" → STOP. Focus on Expression::Operation.
- "tracking which file we're in" → STOP. The span has the file.

The span. Has. Everything. Just. Use. It.

---

## Git Repository Rules

**CRITICAL: NEVER push to any git repository without explicit user permission.**

### Why This Is Critical - The Safe Harbor Principle

Local commits are "safe harbors" - checkpoints the user can return to.

**If LLM can push:**
- Current safe harbor destroyed (work becomes public)
- ALL safe harbors at risk (force push could rewrite history)
- Psychological safety lost (can't experiment freely)
- Entire repository integrity threatened

**The human must control the boundary between:**
- Private (local repo) ← LLM can work here
- Public (remote repo) ← Only human crosses this line

### Rules

- You may stage files (`git add`)
- You may commit files (`git commit`)
- You must ALWAYS ask before running `git push`
- You must NEVER run `git push --force` (EVER)
- Stop after committing and ask: "The changes are committed. Would you like me to push to GitHub now?"
- Wait for explicit "yes" or "push" command from the user before executing any `git push` operation
- This rule applies to ALL branches and ALL remotes
- No exceptions, no shortcuts, no "just this once"

**Push is the irreversible action - human must control it.**

## General Guidelines

- Follow user instructions carefully
- Ask for clarification when uncertain
- Be respectful of the user's workflow and preferences

## Server Process Management

**Always use `lsof` to find and kill processes on specific ports.**

```bash
# Kill process on port 3000
lsof -ti:3000 | xargs kill -9

# Then start new server
cargo run --bin server
```

**Why:**
- `pkill` may not find the right process
- `lsof -ti:PORT` reliably finds the exact process using that port
- Avoids "Address already in use" errors

**Never use:**
- `pkill -f server` (too broad, may miss the target)
- `killall` (imprecise)

## Z3 and Equation Editor Performance Rules

**CRITICAL: The Equation Editor MUST NOT hang waiting for Z3.**

### The Problem: Universal Quantifiers + Evaluation = HANG

When Z3 has axioms with universal quantifiers (∀), asking it to **evaluate** 
concrete expressions causes a combinatorial explosion:

```
Axiom: ∀ x . ∀ xs . nth(cons(x, xs), 0) = x
Query: evaluate(nth([1,2,3], 1))

Z3 E-matching tries ALL possible instantiations of x and xs...
Result: HANGS FOREVER
```

### What Works vs What Hangs

| Operation | Method | Result |
|-----------|--------|--------|
| **Evaluate** `nth([1,2,3], 1)` | Z3 + ∀ axioms | ❌ HANGS |
| **Evaluate** `nth([1,2,3], 1)` | Inline Rust expansion | ✅ Fast |
| **Verify** `g(μ,ν) = g(ν,μ)` satisfiable? | Z3 + ∀ axioms | ✅ Fast |
| **Verify** complex theorem | Z3 + ∀ axioms | ⚠️ May be slow |

### Rules

1. **For concrete computation in Equation Editor:** Use inline Rust expansion
2. **For verification/satisfiability:** Z3 with axioms is OK (with timeout)
3. **Never call Z3 evaluate() with quantified axioms loaded**
4. **Always add timeout for Z3 operations exposed to users**

### Architecture Decision

Axioms are for VERIFICATION ("is this true?"), not EVALUATION ("what is 2+2?").

For evaluation, Rust computes directly and tells Z3 the answer.

## Editor AST vs Kleis AST Architecture

**CRITICAL: There are TWO different ASTs in this project. Do not confuse them.**

### The Two ASTs

| AST Type | Created By | Location | Purpose |
|----------|-----------|----------|---------|
| **Editor AST** | JavaScript | `static/index.html` | Internal representation for Equation Editor |
| **Kleis AST** | Rust Parser | `src/kleis_parser.rs` | Language representation matching grammar |

**They are NOT the same thing.** The Editor AST is internal and can have richer structure.

### Three-Rung Ladder Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│ RUNG 1: Equation Editor (JavaScript in static/index.html)       │
│   User clicks button → generates Editor AST                     │
│   Uses SEMANTIC operation names: 'gamma', 'riemann', 'index_mixed' │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│ RUNG 2: Kleis Renderer (Rust: src/render.rs)                    │
│   Editor AST → visual output (per target)                       │
│   • Typst target: uses template keyed by 'gamma' → Γ^λ_{μν}    │
│   • LaTeX target: uses template keyed by 'gamma'                │
│   • Kleis target: outputs xAct notation → Γ(λ, -μ, -ν)          │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│ RUNG 3: Kleis Language (src/kleis_parser.rs, grammar, Z3)       │
│   Kleis text → parsed to Kleis AST → verified/evaluated         │
│   Example: "Γ(λ, -μ, -ν)" parses to function call with negate() │
└─────────────────────────────────────────────────────────────────┘
```

### Key Rules

1. **Editor AST uses semantic operation names**
   - `gamma` NOT `Γ`
   - `riemann` NOT `R`
   - `index_mixed` NOT `T`
   - These names are keys for Typst/LaTeX/HTML templates

2. **xAct notation (`Γ(λ, -μ, -ν)`) belongs in Kleis text output only**
   - NOT in Editor AST
   - Generated by Kleis Renderer when target is `RenderTarget::Kleis`

3. **Changing Editor AST requires updating ALL renderers**
   - `src/render.rs` (5 targets: Unicode, LaTeX, HTML, Typst, Kleis)
   - `src/typst_renderer.rs`
   - `static/index.html` (JavaScript)
   - Server API endpoints
   - Tests

4. **Templates are keyed by semantic names**
   - Typst templates expect `gamma(base, upper, lower1, lower2)`
   - If you change Editor AST to use `Γ`, Typst rendering breaks

### Common Mistake (Don't Do This)

❌ **WRONG:** Changing Editor AST to use symbols instead of semantic names
```javascript
// DON'T DO THIS - breaks Typst/LaTeX templates
christoffel: { Operation: { name: 'Γ', args: [...] } }
```

✅ **CORRECT:** Editor AST uses semantic names, renderer outputs symbols
```javascript
// Editor AST (JavaScript)
christoffel: { Operation: { name: 'gamma', args: [...] } }

// Kleis Renderer outputs xAct notation for Kleis target
// Typst Renderer uses 'gamma' template
```

### Reference

See `docs/NEXT_SESSION.md` for detailed architecture notes and lessons learned.

## Refactoring and Code Quality Rules

**CRITICAL: No shortcuts, no technical debt, no half-measures.**

### Rule: Actually Use What You Build

**When implementing abstractions or refactoring:**

❌ **WRONG - Adding alongside old code:**
```rust
struct MyModule {
    old_impl: OldWay,      // Keep old code
    new_backend: NewWay,   // Add new abstraction alongside
}
// Result: Duplication, unclear which is used, technical debt
```

✅ **CORRECT - Replace, don't duplicate:**
```rust
struct MyModule {
    backend: NewWay,       // Only the new abstraction
}
// Old code DELETED, not commented out
// All tests verify the new way works
```

**Key Principles:**

1. **Test the abstraction immediately** - Don't just build it, USE it
2. **Remove old code** - Delete it entirely, don't leave it "just in case"
3. **Run full test suite** - Not just unit tests, run ALL tests (cargo test, not --lib)
4. **Verify through tests** - Tests must exercise the new code path

**Example from Session:**
- Built Z3Backend abstraction
- Initially just added it alongside old Solver
- User caught it: "You didn't actually switch to using it!"
- Fixed: Removed 642 lines of duplicate code, all tests through abstraction

### Rule: Remove Dead Code Systematically

**When refactoring, identify what's actually used:**

**Process:**
```
1. Comment out old code (to see what breaks)
2. Run cargo check - see compilation errors
3. Fix each error by using new abstraction
4. Verify with cargo test (ALL tests!)
5. Delete old code completely (don't leave commented out)
6. Run quality gates (fmt, clippy, test)
```

**Don't guess - Let the compiler tell you:**
- Compiler errors show exactly what's still used
- Dead code warnings show what can be deleted
- Don't leave "just in case" code behind

**Why this matters:**
- Technical debt compounds over time
- Unclear which code path is active
- Future maintainers confused
- Tests might not cover new code

### Rule: Think Through Architecture

**Before implementing, ask:**

1. **"What if the feature is disabled?"**
   - Check `#[cfg(not(feature = "..."))]` case
   - Ensure struct fields are properly feature-gated
   
2. **"What state belongs where?"**
   - Backend state vs. high-level state
   - Who owns what data?
   
3. **"Can this be misused?"**
   - Abstraction boundaries clear?
   - Types prevent invalid usage?

**Example from Session:**
- User asked: "What happens if we don't have a backend?"
- Made me realize declared_ops should be in backend, not verifier
- Proper ownership: backend tracks its own state

### Rule: Quality Gates Are Not Optional

**NEVER skip quality checks to "save time":**

```bash
# ALWAYS run all three:
cargo fmt --all
cargo clippy --all-targets --all-features  
cargo test  # NOT cargo test --lib, run ALL tests!
```

**Why each matters:**
- **fmt:** Pre-push hook will reject unformatted code
- **clippy:** Catches bugs and anti-patterns
- **test:** Proves your changes actually work

**If you skip them:**
- GitHub CI will fail (wastes time)
- Pre-push hook blocks you (embarrassing)
- Bugs slip through (costly)

**The Architect's Motto:**
"No shortcuts for getting a clean build or saving time. Don't make tests lenient. If you're about to change or delete tests, ask first."

## Website Stats Update Rule

**CRITICAL: Update kleis.io landing page stats at the start of each session.**

### Rule: Update GitHub Traffic Stats

**At the beginning of each session (or when requested):**

1. **Check GitHub Traffic** 
   - Visit: https://github.com/eatikrh/kleis/graphs/traffic
   - Note current "Unique cloners" count
   - Note current "Commits" count from main page

2. **Count Research Papers**
   - Count PDF files in `docs/mathematics/`
   - Current count should match dynamic counter

3. **Update Landing Page Static Stats** (if needed)
   - File: `index.html`
   - Update any hardcoded numbers or date references
   - Example: "286+ Cloners (Dec 2024)" → new count

4. **Document the update**
   - Log format: "Updated kleis.io stats: X cloners, Y commits, Z papers"

**Current stats (as of Dec 11, 2024):**
- Unique Cloners: 310+ (was 286+ this morning, 297+, 306+ - rapid growth!)
- GitHub Stars: 0
- Commits: 504
- Architecture Decisions: 22 ADRs

**Why this matters:**
- Shows active development and community interest
- Cloner count is private (requires auth) - must be manually updated
- Other stats (stars, commits, papers) are dynamic via GitHub API
- Helps track project growth over time

## Efficient Test Running

**CRITICAL: Don't recompile the entire project when running a single test.**

### Rules

1. **Don't run `cargo check` before `cargo test`** - wasteful, test compiles anyway
2. **Run tests directly:** `cargo test --test test_name -- --nocapture`
3. **If only the test file changed** - compilation should be fast (seconds, not minutes)
4. **If library files changed** - recompilation is unavoidable, but only run once

### What Triggers Full Recompilation

| Change | Recompile? |
|--------|-----------|
| Test file only (`tests/*.rs`) | NO - just recompile test |
| Library file (`src/*.rs`) | YES - must recompile library |
| `cargo check` then `cargo test` | YES - different profiles! |

### Avoid This Pattern

```bash
# WASTEFUL - compiles twice!
cargo check
cargo test --test my_test
```

### Do This Instead

```bash
# Just run the test directly
cargo test --test my_test -- --nocapture
```

## Rust Code Quality Rules

**CRITICAL: Run quality checks before committing .rs files.**

### Rule: Pre-Commit Quality Gates

**Before committing any Rust code changes:**

1. **Format code** (required)
   ```bash
   cargo fmt --all
   ```
   - Ensures consistent code style across ALL crates (including render/)
   - GitHub CI will fail if formatting is incorrect
   - Run automatically before every commit
   - **CRITICAL:** Use `--all` flag to format workspace members

2. **Run clippy** (required)
   ```bash
   export Z3_SYS_Z3_HEADER=/opt/homebrew/opt/z3/include/z3.h && cargo clippy --all-targets --all-features
   ```
   - **Note:** Z3 environment variable required for build
   - Catches common mistakes and anti-patterns
   - Fix all clippy warnings before committing
   - GitHub CI runs this check
   - **macOS Intel:** Use `/usr/local/opt/z3/include/z3.h`
   - **Linux:** Use `/usr/include/z3.h`

3. **Run tests** (required)
   ```bash
   export Z3_SYS_Z3_HEADER=/opt/homebrew/opt/z3/include/z3.h && cargo test
   ```
   - **Note:** Z3 environment variable required for build
   - Runs ALL tests: unit tests + integration tests
   - Ensures no regressions in any component
   - Must pass (421+ unit tests, all integration tests as of Dec 11, 2024)
   - **CRITICAL:** Do NOT use `--lib` flag - it skips integration tests!
   - GitHub CI runs both unit and integration tests
   - **macOS Intel:** Use `/usr/local/opt/z3/include/z3.h`
   - **Linux:** Use `/usr/include/z3.h`

**Process:**
```
Before committing .rs files:
→ Run: cargo fmt --all
→ Run: export Z3_SYS_Z3_HEADER=/opt/homebrew/opt/z3/include/z3.h && cargo clippy --all-targets --all-features
→ Run: export Z3_SYS_Z3_HEADER=/opt/homebrew/opt/z3/include/z3.h && cargo test
→ Fix any errors/warnings
→ Then commit

If tests fail:
→ Fix the code OR
→ Document why test should be ignored
→ Never commit broken tests
```

**Why this matters:**
- Prevents CI failures
- Maintains code quality
- Catches bugs early
- Ensures consistent style
- Professional development practice

**GitHub CI checks these exact commands:**
- `cargo fmt -- --check` (formatting)
- `cargo clippy --all-targets --all-features -- -D warnings` (linting)
- `cargo test --lib --verbose` (tests)

**Exceptions:**
- Quick documentation-only commits (no .rs files changed): skip
- Clippy warnings in legacy code: can continue-on-error, but fix if possible
- Known test failures: documented in test files with `#[ignore]`

## Parser Development Rules

**CRITICAL: Parser changes must align with formal grammar.**

### Rule: Grammar Consistency Check

**When modifying `src/kleis_parser.rs`:**

1. **Check against formal grammar** in `docs/grammar/kleis_grammar_v05.ebnf` or `docs/grammar/Kleis_v05.g4`
2. **Verify change is valid** according to formal specification
3. **Document any deviations** with rationale
4. **Update grammar if needed** (requires ADR if significant)

**Grammar files:**
- `docs/grammar/kleis_grammar_v05.ebnf` - EBNF specification (source of truth)
- `docs/grammar/Kleis_v05.g4` - ANTLR4 grammar
- `docs/grammar/kleis_grammar_v05.md` - Human-readable explanation

**Process:**
```
Before changing parser:
→ Read relevant grammar section
→ Verify change matches specification
→ If deviation needed, document why

After changing parser:
→ Test with examples from grammar
→ Update grammar docs if specification changed
→ Note any limitations in parser file comments
```

**Why this matters:**
- Parser is ~30% of full grammar (by design, POC)
- Must stay aligned with formal specification
- Prevents drift between implementation and design
- Makes future full parser implementation easier

## Type System Rules

**CRITICAL: Follow ADR-014 (Hindley-Milner Type System) and ADR-016 (Operations in Structures).**

### Rule: Maintain Type System Integrity (ADR-014)

**The type system must follow Hindley-Milner principles.**

**Core Principles:**

1. **Constraint-based inference** - Generate constraints, then unify
2. **Principal types** - Always infer the most general type
3. **No shortcuts** - Don't bypass unification or constraint solving
4. **Context threading** - Pass `context_builder` through call chain

**❌ WRONG - Bypassing type inference:**
```rust
// Hardcoding result type without inference
fn check_multiply(t1: Type, t2: Type) -> Type {
    Type::Matrix(2, 2)  // BAD! Ignores actual dimensions
}

// Skipping constraint generation
let t1 = self.infer(&args[0], context_builder)?;
// Just return without adding constraints  // BAD!
return Ok(Type::Scalar);
```

**✅ CORRECT - Proper HM inference:**
```rust
// Generate constraints
let t1 = self.infer(&args[0], context_builder)?;
let t2 = self.infer(&args[1], context_builder)?;
self.add_constraint(t1.clone(), t2.clone());

// Delegate to context_builder for operation types
if let Some(builder) = context_builder {
    builder.infer_operation_type(name, &[t1, t2])
} else {
    Ok(self.context.fresh_var())
}
```

**When modifying type inference:**
1. **Always generate constraints** - Don't hardcode results
2. **Always delegate operations** - Use `context_builder.infer_operation_type()`
3. **Always thread context** - Pass `context_builder` through recursive calls
4. **Always unify** - Let the solver determine types

**Key Files:**
- `src/type_inference.rs` - Core HM algorithm
- `src/type_context.rs` - Type registry and queries
- `src/type_checker.rs` - Combines inference + registry
- `stdlib/*.kleis` - Type definitions (source of truth)

**Related ADRs:**
- ADR-014: Hindley-Milner Type System (the algorithm)
- ADR-016: Operations in Structures (the architecture)
- ADR-015: Text as Source of Truth (where types are defined)

---

### Rule: No Hardcoding Types (ADR-016)

**Types and operations MUST be defined in Kleis structures, NOT hardcoded in Rust.**

**❌ WRONG - Hardcoded in type_inference.rs:**
```rust
"matrix2x3" => Ok(Type::Matrix(2, 3))  // BAD!
"matmul" => /* hardcoded matrix multiplication logic */  // BAD!
```

**✅ CORRECT - Defined in stdlib/*.kleis:**
```kleis
structure Matrix(m: Nat, n: Nat, T) {
    operation transpose : Matrix(n, m, T)
}

implements Matrix(m, n, ℝ) {
    operation transpose = builtin_transpose
}
```

**Then type inference queries the registry:**
```rust
// Query: What type does "matrix2x3" produce?
let ty = type_checker.infer_from_registry("matrix2x3", args)?;

// Query: Does Matrix(2,3) support multiply with Matrix(3,2)?  
let result_ty = type_checker.check_operation("multiply", &[t1, t2])?;
```

**Why this matters:**
- **Extensibility:** Users can define custom types without changing Rust code
- **Consistency:** Single source of truth (stdlib/*.kleis files)
- **Self-hosting:** Kleis defines itself in Kleis (ADR-003)
- **Maintainability:** Type rules live with their structures

**Exceptions:**
- **Built-in primitives only:** Scalar, basic arithmetic (+, -, *, /)
- **Everything else:** Define in stdlib/*.kleis structures

**When tempted to hardcode:**
1. Stop and ask: "Should this be a structure?"
2. If yes: Create/update stdlib/*.kleis file
3. Make type inference query the registry
4. Document the structure with axioms

**Related ADRs:**
- ADR-016: Operations in Structures (the foundation)
- ADR-015: Text as Source of Truth (applies to types too)
- ADR-003: Self-Hosting Strategy (Kleis defines Kleis)

## Documentation Link Quality Gate

**CRITICAL: All markdown links must be valid before committing documentation.**

### Rule: Check Markdown Links

**Before committing any .md files:**

```bash
python3 scripts/check_markdown_links.py
```

- Must show **0 broken links**
- Script checks all .md files (excluding node_modules, target)
- Ignores code blocks and mathematical notation
- Only checks actual documentation links (.md, .rs, .kleis, etc.)

**Why this matters:**
- Documentation moves and reorganizes frequently
- Broken links create poor user experience
- Quality standard prevents documentation rot
- Maintains professional appearance

**Process:**
```
Before committing .md files:
→ Run: python3 scripts/check_markdown_links.py
→ If any broken links found:
   - Fix all broken links
   - Re-run check until 0 broken links
→ Only then commit
→ Never commit with broken links
```

**Link Checker Features:**
- Excludes code blocks (``````...```````)
- Ignores inline code (`...`)  
- Skips mathematical notation ([f](x), [exp(-t²)](ω))
- Validates file extensions (.md, .rs, .kleis, .html, .pdf, etc.)
- Reports exact file location and target path for each broken link

## Documentation Organization Rules

**When creating documentation during a session:**

1. **Combine overlapping content** - Review documents for redundancy and consolidate
2. **Check for obsolete documents** - Remove or archive documents that are superseded
3. **Organize into subdirectories** - Don't leave many documents in root `docs/`
   - Use `docs/session-YYYY-MM-DD/` for session-specific work
   - Use `docs/notation/`, `docs/parser-implementation/`, `docs/type-system/` etc. for topic-specific docs
   - Keep only ADRs and main reference docs in root
4. **Create session README** - Summarize session work in `docs/session-YYYY-MM-DD/README.md`
5. **Update main README** - Keep `docs/README.md` as the navigation index

**Session archival policy:**

Sessions should be moved to `docs/archive/sessions/` after ~2 weeks:

```bash
# At start of session, check session folder dates
cd docs && ls -lt session-* | head -5

# If sessions older than 2 weeks exist, archive them:
cd docs && mv session-YYYY-MM-DD archive/sessions/

# Update docs/archive/sessions/README.md with archived session info
```

**Keep in docs/ root:**
- Last 2-3 active sessions only
- Current work-in-progress

**Move to archive when:**
- ✅ Content consolidated into permanent docs (ADRs, reference docs)
- ✅ Key findings captured elsewhere
- ✅ No longer actively referenced
- ✅ Older than ~2 weeks

**Benefits:**
- Clean docs/ directory
- Recent sessions easily discoverable
- Historical sessions preserved but not cluttering
- Clear signal of what's current vs historical

**Cleanup checklist before ending session:**
- [ ] Consolidate overlapping documents
- [ ] Move session-specific docs to session folder
- [ ] Move technical docs to appropriate subdirectories  
- [ ] Delete obsolete/temporary documents
- [ ] Update docs/README.md with navigation
- [ ] Create session README summarizing work
- [ ] **Check for sessions older than 2 weeks and archive them**

## Project Root Organization Rules

**Keep project root clean:**

1. **Generated reports** - Keep in root if they show current state
   - `comparison_report.html` - Test comparison (useful for viewing)
   - `html_gallery.html` - Rendering gallery (useful for viewing)
   - `template_coverage_report.html` - Template coverage (useful for viewing)
   - These are snapshots showing current system state

2. **No loose markdown files in root** - Except:
   - README.md
   - CHANGELOG.md
   - LICENSE
   - CONTRIBUTING.md (if exists)
   - PARSER_TODO.md, SERVER_README.md (project docs)

3. **Temporary files** - Add to .gitignore:
   - `tmp_*.html`, `tmp_*.pdf`
   - Build artifacts
   - Editor temp files

## Aspirational Documentation Check

**Periodically check that manual examples match parser implementation.**

The Kleis manual may contain "aspirational" code examples - syntax that is
documented but not yet implemented in the parser. Use this command to find them:

```bash
python3 scripts/validate_manual_examples.py --strict --verbose
```

**Options:**
- `--strict`: Actually run `kleis --check` on each code block
- `--verbose`: Show temp file paths and commands being run
- `--show`: Display all extracted code blocks for review

**What it catches:**
- Unicode operators (∧, ∨) not yet in parser
- `where` clauses in structures
- Parameterized data types
- Dot notation in imports
- Any syntax in the book that the parser can't parse

**Policy:**
- Aspirational docs don't block pushing (pre-push hook uses non-strict mode)
- Run `--strict` periodically to track implementation gaps
- When implementing a feature, check if manual already documents it
- When documenting a feature, ensure parser supports it first

**Suggested frequency:** Run at start of each session or before major releases.

