// ============================================================================
// KleisDoc - Auto-generated document file
// ============================================================================
//
// This file was generated by KleisDoc Python API.
// It can be loaded back into KleisDoc for continued editing.
//
// ============================================================================

import "examples/documents/kleisdoc_types.kleis"

// ----------------------------------------------------------------------------
// Document Metadata
// ----------------------------------------------------------------------------

define meta_title = "Neural Network Approaches to Quantum Error Correction: Theory, Implementation, and Experimental Validation"
define meta_authors = List(
    Author(name = "Alexandra Chen", email = "achen@umich.edu", affiliation = "University of Michigan", role = "primary")
)
define meta_date = "2026"
define meta_abstract = "\n    Quantum computing promises revolutionary advances in computational capability, \n    yet remains fundamentally limited by decoherence and gate errors. This dissertation \n    presents a comprehensive framework for neural network-based quantum error correction \n    (NNQEC) that achieves state-of-the-art performance on both simulated and experimental \n    quantum systems.\n\n    We begin by establishing the theoretical foundations of quantum error correction, \n    introducing a novel mathematical framework that unifies stabilizer codes with \n    machine learning optimization objectives. Our key theoretical contribution is the \n    proof that neural decoders can achieve the maximum likelihood decoding threshold \n    for any stabilizer code, resolving a long-standing open question in the field.\n\n    The dissertation then presents three major algorithmic innovations: (1) a \n    transformer-based architecture for syndrome decoding that achieves 99.7% accuracy \n    on the surface code, (2) a reinforcement learning approach to adaptive error \n    correction that outperforms static decoders by 23%, and (3) a variational quantum \n    eigensolver enhanced by neural error mitigation that enables chemistry simulations \n    on near-term devices.\n\n    We validate our methods through extensive experiments on IBM and Google quantum \n    processors, demonstrating practical improvements in logical error rates. Our \n    neural decoder reduces the physical qubit overhead required for fault-tolerant \n    computation by approximately 40%, representing a significant step toward \n    practical quantum advantage.\n\n    The dissertation concludes with a roadmap for scaling these techniques to \n    larger quantum systems and discusses implications for the timeline of \n    fault-tolerant quantum computing.\n    "

// ----------------------------------------------------------------------------
// Equations (with EditorNode AST for re-editing)
// ----------------------------------------------------------------------------

define error_rate = Equation(
    id = "eq_0",
    label = "error_rate",
    latex = "p_{logical} = A \\cdot p_{physical}^{\\lfloor (d+1)/2 \\rfloor}",
    typst = "",
    ast = None,
    numbered = true,
    verified = false
)

define pauli_group = Equation(
    id = "eq_1",
    label = "pauli_group",
    latex = "\\mathcal{P}_n = \\{ i^k P_1 \\otimes P_2 \\otimes \\cdots \\otimes P_n : k \\in \\{0,1,2,3\\}, P_i \\in \\{I, X, Y, Z\\} \\}",
    typst = "",
    ast = None,
    numbered = true,
    verified = false
)

define stabilizer_condition = Equation(
    id = "eq_2",
    label = "stabilizer_condition",
    latex = "|\\\\psi\\\\rangle \\\\in \\\\mathcal{C} \\\\iff S|\\\\psi\\\\rangle = |\\\\psi\\\\rangle \\\\quad \\\\forall S \\\\in \\\\mathcal{S}",
    typst = "",
    ast = None,
    numbered = true,
    verified = false
)

define surface_threshold = Equation(
    id = "eq_3",
    label = "surface_threshold",
    latex = "p_{th} \\\\approx 1.1\\\\%",
    typst = "",
    ast = None,
    numbered = true,
    verified = false
)

define ml_decoding = Equation(
    id = "eq_4",
    label = "ml_decoding",
    latex = "\\\\hat{E} = \\\\arg\\\\max_{E} P(E|s) = \\\\arg\\\\max_{E} \\\\frac{P(s|E)P(E)}{P(s)}",
    typst = "",
    ast = None,
    numbered = true,
    verified = false
)

define universal_approx = Equation(
    id = "eq_5",
    label = "universal_approx",
    latex = "P(f(s) = E^*) \\\\geq P_{ML}(s) - \\\\epsilon",
    typst = "",
    ast = None,
    numbered = true,
    verified = false
)

define sample_complexity = Equation(
    id = "eq_6",
    label = "sample_complexity",
    latex = "N = O\\\\left(\\\\frac{d^2 \\\\log(1/\\\\eta)}{\\\\delta^2}\\\\right)",
    typst = "",
    ast = None,
    numbered = true,
    verified = false
)

define training_loss = Equation(
    id = "eq_7",
    label = "training_loss",
    latex = "\\\\mathcal{L} = \\\\mathcal{L}_{CE} + \\\\lambda \\\\mathcal{L}_{sym}",
    typst = "",
    ast = None,
    numbered = true,
    verified = false
)

define reward = Equation(
    id = "eq_8",
    label = "reward",
    latex = "r_t = \\\\mathbb{1}[\\\\text{logical measurement correct}]",
    typst = "",
    ast = None,
    numbered = true,
    verified = false
)

define vqe_objective = Equation(
    id = "eq_9",
    label = "vqe_objective",
    latex = "E(\\\\theta) = \\\\langle 0| U^{\\\\dagger}(\\\\theta) H U(\\\\theta) |0\\\\rangle",
    typst = "",
    ast = None,
    numbered = true,
    verified = false
)

define mitigation = Equation(
    id = "eq_10",
    label = "mitigation",
    latex = "\\\\tilde{E} = f_{\\\\phi}(E_{noisy}, \\\\theta, \\\\text{context})",
    typst = "",
    ast = None,
    numbered = true,
    verified = false
)

// ----------------------------------------------------------------------------
// Figures (with Kleis code for regeneration)
// ----------------------------------------------------------------------------

define performance_plot = Figure(
    id = "fig_0",
    label = "performance_plot",
    caption = "Logical error rate vs physical error rate for TransformerQEC compared to baseline decoders",
    source = Regenerable("plot([0.001, 0.005, 0.01, 0.015], [1e-6, 1e-4, 0.01, 0.1])", List()),
    typst_fragment = "",
    svg_cache = ""
)

// ----------------------------------------------------------------------------
// Tables
// ----------------------------------------------------------------------------

define code_comparison = Table(
    label = "code_comparison",
    headers = List("Code", "Distance", "Physical Qubits", "Threshold"),
    rows = List(List("Steane [[7,1,3]]", "3", "7", "~0.1%"), List("Surface [[d²,1,d]]", "d", "d²", "~1.1%"), List("Color [[18,2,4]]", "4", "18", "~0.8%"), List("LDPC [[n,k,d]]", "varies", "varies", "~5-10%")),
    caption = "Comparison of quantum error correction codes",
    kleis_code = ""
)

define transformer_params = Table(
    label = "transformer_params",
    headers = List("Parameter", "Value", "Description"),
    rows = List(List("Embedding dim", "256", "Hidden dimension"), List("Attention heads", "8", "Multi-head attention"), List("Transformer layers", "6", "Depth"), List("FFN dim", "1024", "Feed-forward dimension"), List("Dropout", "0.1", "Regularization")),
    caption = "TransformerQEC architecture parameters",
    kleis_code = ""
)

define benchmark_results = Table(
    label = "benchmark_results",
    headers = List("Code Distance", "MWPM", "Union-Find", "TransformerQEC"),
    rows = List(List("d=3", "94.2%", "93.8%", "96.1%"), List("d=5", "91.7%", "91.2%", "94.8%"), List("d=7", "88.3%", "87.9%", "92.4%"), List("d=9", "84.1%", "83.5%", "89.7%"), List("d=11", "79.2%", "78.4%", "86.3%")),
    caption = "Decoding accuracy under 1% depolarizing noise",
    kleis_code = ""
)

define adaptive_results = Table(
    label = "adaptive_results",
    headers = List("Noise Type", "Static Decoder", "AdaptiveQEC", "Improvement"),
    rows = List(List("Constant", "89.2%", "89.4%", "+0.2%"), List("Slow drift", "82.1%", "87.3%", "+5.2%"), List("Fast drift", "71.4%", "86.8%", "+15.4%"), List("Sudden shift", "68.9%", "84.2%", "+15.3%")),
    caption = "Decoding accuracy under time-varying noise models",
    kleis_code = ""
)

define chemistry_results = Table(
    label = "chemistry_results",
    headers = List("Molecule", "Qubits", "VQE Error (mHa)", "NeuralVQE Error (mHa)"),
    rows = List(List("H₂", "4", "3.2", "0.4"), List("LiH", "8", "8.7", "1.2"), List("BeH₂", "12", "15.3", "2.8"), List("H₂O", "14", "22.1", "4.1")),
    caption = "Energy estimation errors on molecular benchmarks",
    kleis_code = ""
)

define ibm_results = Table(
    label = "ibm_results",
    headers = List("Metric", "MWPM", "TransformerQEC"),
    rows = List(List("Logical X error", "4.2%", "2.8%"), List("Logical Z error", "3.9%", "2.5%"), List("Combined", "5.7%", "3.7%"), List("Latency (μs)", "12.3", "8.7")),
    caption = "Experimental results on IBM Eagle processor",
    kleis_code = ""
)

// ----------------------------------------------------------------------------
// Bibliography
// ----------------------------------------------------------------------------

define bib_shor1995 = BibEntry(
    key = "shor1995",
    entry_type = "article",
    title = "Scheme for reducing decoherence in quantum computer memory",
    authors = "Shor, P. W.",
    year = "1995",
    journal = "Physical Review A",
    volume = "",
    pages = "",
    publisher = "",
    doi = "",
    url = "",
    note = ""
)

define bib_kitaev2003 = BibEntry(
    key = "kitaev2003",
    entry_type = "article",
    title = "Fault-tolerant quantum computation by anyons",
    authors = "Kitaev, A. Y.",
    year = "2003",
    journal = "Annals of Physics",
    volume = "",
    pages = "",
    publisher = "",
    doi = "",
    url = "",
    note = ""
)

define bib_fowler2012 = BibEntry(
    key = "fowler2012",
    entry_type = "article",
    title = "Surface codes: Towards practical large-scale quantum computation",
    authors = "Fowler, A. G. and Mariantoni, M. and Martinis, J. M. and Cleland, A. N.",
    year = "2012",
    journal = "Physical Review A",
    volume = "",
    pages = "",
    publisher = "",
    doi = "",
    url = "",
    note = ""
)

define bib_vaswani2017 = BibEntry(
    key = "vaswani2017",
    entry_type = "inproceedings",
    title = "Attention is all you need",
    authors = "Vaswani, A. and others",
    year = "2017",
    journal = "NeurIPS",
    volume = "",
    pages = "",
    publisher = "",
    doi = "",
    url = "",
    note = ""
)

define bib_torlai2017 = BibEntry(
    key = "torlai2017",
    entry_type = "article",
    title = "Neural network quantum state tomography",
    authors = "Torlai, G. and others",
    year = "2018",
    journal = "Nature Physics",
    volume = "",
    pages = "",
    publisher = "",
    doi = "",
    url = "",
    note = ""
)

define bib_google2023 = BibEntry(
    key = "google2023",
    entry_type = "article",
    title = "Suppressing quantum errors by scaling a surface code logical qubit",
    authors = "Google Quantum AI",
    year = "2023",
    journal = "Nature",
    volume = "",
    pages = "",
    publisher = "",
    doi = "",
    url = "",
    note = ""
)

// ----------------------------------------------------------------------------
// Document Structure
// ----------------------------------------------------------------------------

define section_0 = Section(
    level = 1,
    title = "Dedication",
    label = None,
    content = List(Text("\nTo my parents, Wei and Lin Chen, who taught me that the pursuit of knowledge \nis the highest calling. To my partner, Michael, whose unwavering support made \nthis journey possible. And to my advisor, Professor Sarah Williams, who showed \nme what it means to be a scientist.\n"))
)

define section_1 = Section(
    level = 1,
    title = "Acknowledgments",
    label = None,
    content = List(Text("\nThis dissertation would not have been possible without the support and guidance \nof many individuals. First and foremost, I am deeply grateful to my advisor, \nProfessor Sarah Williams, whose brilliance, patience, and mentorship have shaped \nme as a researcher. Her vision for the intersection of machine learning and \nquantum computing inspired this entire body of work.\n\nI thank my committee members—Professors David Liu, Jennifer Martinez, and \nRobert Thompson—for their insightful feedback and challenging questions that \nstrengthened this research. The quantum computing group at Michigan has been \nan incredible intellectual home, and I am grateful to my lab mates for countless \ndiscussions and collaborations.\n\nThis research was supported by the National Science Foundation (Grant No. \nPHY-2112893), the Department of Energy (DE-SC0019380), and the Google Quantum \nAI Research Award. I am grateful for access to IBM Quantum and Google Quantum \nAI hardware through their academic programs.\n\nFinally, I thank my family for their love and encouragement. My parents' \nsacrifices made my education possible, and my partner Michael's patience \nduring late nights and weekends of writing kept me going.\n"))
)

define section_2 = Section(
    level = 1,
    title = "Introduction",
    label = "ch:intro",
    content = List(Text("\nThe quest for practical quantum computing stands at a critical juncture. While \nremarkable progress has been made in building quantum processors with increasing \nnumbers of qubits, the fundamental challenge of quantum error correction remains \nthe primary barrier to achieving computational advantage for practical problems. \nThis dissertation addresses this challenge through the lens of machine learning, \ndeveloping neural network approaches that push the boundaries of what is possible \nwith near-term quantum devices.\n"), SectionRef("section_2_sub0"), EqRef("error_rate"), Text("\nEquation 1 shows the logical error rate as a function of the physical error rate \nfor a distance-d code, where A is a constant depending on the code. The key \ninsight is that below a threshold physical error rate, increasing the code \ndistance exponentially suppresses logical errors.\n"), SectionRef("section_2_sub1"), SectionRef("section_2_sub2"), SectionRef("section_2_sub3"))
)

define section_2_sub0 = Section(
    level = 2,
    title = "Motivation and Context",
    label = "sec:motivation",
    content = List(Text("\nQuantum computers exploit the principles of superposition and entanglement to \nperform computations that would be intractable on classical machines. The promise \nof exponential speedups for problems in cryptography, optimization, and quantum \nsimulation has driven billions of dollars of investment from governments and \nindustry. Yet current quantum processors, often termed Noisy Intermediate-Scale \nQuantum (NISQ) devices, are fundamentally limited by errors.\n\nEvery quantum gate introduces errors at rates of approximately 0.1-1%, and \nquantum states decohere on timescales of microseconds to milliseconds. For \nalgorithms requiring millions of gates, the accumulated errors render the \ncomputation meaningless without active error correction. The standard approach \nto quantum error correction (QEC) encodes logical qubits into many physical \nqubits, using redundancy to detect and correct errors.\n"))
)

define section_2_sub1 = Section(
    level = 2,
    title = "Challenges in Quantum Error Correction",
    label = "sec:challenges",
    content = List(Text("\nWhile the theory of quantum error correction is well-established, practical \nimplementation faces several challenges:\n\n1. **Decoding Complexity**: Optimal decoding of quantum error correction codes \n   is computationally hard in general. Maximum likelihood decoding is NP-hard \n   for most codes of interest, necessitating approximate algorithms.\n\n2. **Real-time Requirements**: Error syndromes must be processed and corrections \n   applied within the coherence time of the quantum system, typically \n   microseconds. This places severe constraints on decoder latency.\n\n3. **Correlated Errors**: Real quantum devices exhibit correlated errors due to \n   crosstalk, cosmic rays, and other environmental factors. Standard decoders \n   assume independent errors and perform poorly on correlated noise.\n\n4. **Overhead**: Current estimates suggest that millions of physical qubits \n   may be required for useful fault-tolerant computation, far exceeding the \n   capabilities of near-term devices.\n\nThis dissertation addresses these challenges through neural network approaches \nthat learn to decode efficiently, operate in real-time, adapt to correlated \nnoise, and reduce qubit overhead.\n"))
)

define section_2_sub2 = Section(
    level = 2,
    title = "Contributions",
    label = "sec:contributions",
    content = List(Text("\nThis dissertation makes the following contributions to the field:\n\n**Theoretical Contributions:**\n- A unified mathematical framework connecting stabilizer codes with neural \n  network optimization (Chapter 2)\n- Proof that neural decoders can achieve maximum likelihood performance for \n  any stabilizer code under mild assumptions (Theorem 2.3)\n- Analysis of the sample complexity of learning quantum decoders (Chapter 3)\n\n**Algorithmic Contributions:**\n- TransformerQEC: A transformer-based architecture for syndrome decoding that \n  achieves state-of-the-art accuracy on the surface code (Chapter 4)\n- AdaptiveQEC: A reinforcement learning approach to adaptive error correction \n  that outperforms static decoders on time-varying noise (Chapter 5)\n- NeuralVQE: A variational quantum eigensolver with neural error mitigation \n  for near-term chemistry simulations (Chapter 6)\n\n**Experimental Contributions:**\n- Demonstration of neural decoding on IBM and Google quantum processors, \n  achieving practical improvements in logical error rates (Chapter 7)\n- Open-source implementation of all algorithms, enabling reproducibility \n  and further research (Appendix A)\n"))
)

define section_2_sub3 = Section(
    level = 2,
    title = "Dissertation Outline",
    label = "sec:outline",
    content = List(Text("\nThe remainder of this dissertation is organized as follows:\n\n**Chapter 2** establishes the theoretical foundations, reviewing quantum error \ncorrection and introducing our mathematical framework.\n\n**Chapter 3** develops the theory of neural quantum decoding, including \nexpressiveness results and sample complexity bounds.\n\n**Chapter 4** presents TransformerQEC, our transformer-based decoder architecture, \nwith detailed architecture design and training methodology.\n\n**Chapter 5** introduces AdaptiveQEC, applying reinforcement learning to \nadaptive error correction for time-varying noise.\n\n**Chapter 6** describes NeuralVQE, integrating neural error mitigation with \nvariational quantum algorithms for chemistry applications.\n\n**Chapter 7** presents experimental validation on real quantum hardware.\n\n**Chapter 8** concludes with a discussion of implications and future directions.\n"))
)

define section_3 = Section(
    level = 1,
    title = "Theoretical Foundations",
    label = "ch:theory",
    content = List(Text("\nThis chapter establishes the theoretical foundations required for the remainder \nof the dissertation. We begin with a review of quantum error correction, \nfocusing on stabilizer codes and the surface code. We then introduce our \nmathematical framework that unifies error correction with machine learning.\n"), SectionRef("section_3_sub0"), EqRef("pauli_group"), Text("\nThe Pauli group on n qubits, shown in Equation 2, forms the basis for stabilizer \ncodes. A stabilizer code is defined by an abelian subgroup S of the Pauli group \nthat does not contain -I. The code space is the simultaneous +1 eigenspace of \nall stabilizers.\n"), EqRef("stabilizer_condition"), SectionRef("section_3_sub1"), EqRef("surface_threshold"), Text("\nThe surface code has an error threshold of approximately 1.1% under \nphenomenological noise, meaning that if physical error rates are below this \nthreshold, increasing the code distance will exponentially suppress logical \nerrors. This threshold is achievable with current superconducting qubit \ntechnology.\n"), SectionRef("section_3_sub2"), EqRef("ml_decoding"), Text("\nThis Bayesian formulation reveals that decoding is equivalent to posterior \ninference in a probabilistic graphical model. The likelihood P(s|E) is \ndetermined by the code structure, while the prior P(E) encodes assumptions \nabout the noise model.\n"))
)

define section_3_sub0 = Section(
    level = 2,
    title = "Quantum Error Correction",
    label = "sec:qec",
    content = List(Text("\nQuantum error correction protects quantum information from decoherence and \ngate errors by encoding logical qubits into larger Hilbert spaces. The \nfundamental principle is that quantum errors form a continuous manifold, \nbut can be digitized into a discrete set of correctable errors.\n"))
)

define section_3_sub1 = Section(
    level = 2,
    title = "The Surface Code",
    label = "sec:surface",
    content = List(Text("\nThe surface code is currently the leading candidate for large-scale quantum \nerror correction due to its high threshold and local stabilizer measurements. \nIt encodes one logical qubit into a two-dimensional array of physical qubits, \nwith X-type and Z-type stabilizers arranged in a checkerboard pattern.\n"))
)

define section_3_sub2 = Section(
    level = 2,
    title = "Unified Framework",
    label = "sec:framework",
    content = List(Text("\nWe now introduce our unified mathematical framework that connects quantum \nerror correction with machine learning optimization. The key insight is that \nthe decoding problem can be formulated as a structured prediction task.\n\nGiven a syndrome s, the decoder must predict the most likely error class E. \nThis is equivalent to finding:\n"))
)

define section_4 = Section(
    level = 1,
    title = "Neural Quantum Decoding Theory",
    label = "ch:neural_theory",
    content = List(Text("\nThis chapter develops the theoretical foundations for neural quantum decoding. \nWe prove that neural networks can represent optimal decoders for any stabilizer \ncode and analyze the sample complexity of learning such decoders.\n"), SectionRef("section_4_sub0"), EqRef("universal_approx"), Text("\nwhere E* is the maximum likelihood error and P_ML(s) is the ML decoding \nsuccess probability. The network size scales polynomially with the code \ndistance and inverse polynomially with ε.\n\n**Proof sketch:** We construct the neural network in three stages. First, we \nshow that the syndrome-to-error mapping can be represented as a composition \nof local functions on the factor graph of the code. Second, we use the \nuniversal approximation theorem to show that each local function can be \napproximated by a neural network. Third, we bound the accumulated error \nusing concentration inequalities.\n"), SectionRef("section_4_sub1"), EqRef("sample_complexity"), Text("\nThis quadratic scaling in code distance is significantly better than the \nexponential scaling required for exact enumeration of error configurations.\n"))
)

define section_4_sub0 = Section(
    level = 2,
    title = "Expressiveness of Neural Decoders",
    label = "sec:express",
    content = List(Text("\nA fundamental question is whether neural networks can represent optimal \ndecoders. We prove that under mild assumptions, neural networks can achieve \nmaximum likelihood decoding performance for any stabilizer code.\n\n**Theorem 3.1 (Universal Approximation for Decoders):** Let C be any stabilizer \ncode with syndrome space S and error space E. For any ε > 0, there exists a \nneural network f: S → E such that:\n"))
)

define section_4_sub1 = Section(
    level = 2,
    title = "Sample Complexity",
    label = "sec:sample",
    content = List(Text("\nBeyond expressiveness, we must understand how many training samples are \nrequired to learn an effective decoder. We prove sample complexity bounds \nthat guide practical training procedures.\n\n**Theorem 3.2 (Sample Complexity Bound):** To learn a decoder achieving \nerror rate at most δ above optimal with probability 1-η, it suffices to \nuse N samples where:\n"))
)

define section_5 = Section(
    level = 1,
    title = "TransformerQEC: Transformer-Based Decoding",
    label = "ch:transformer",
    content = List(Text("\nThis chapter presents TransformerQEC, our transformer-based architecture for \nquantum error correction decoding. We describe the architecture design, \ntraining methodology, and benchmark results.\n"), SectionRef("section_5_sub0"), SectionRef("section_5_sub1"), EqRef("training_loss"), SectionRef("section_5_sub2"), FigRef("performance_plot"))
)

define section_5_sub0 = Section(
    level = 2,
    title = "Architecture Design",
    label = "sec:arch",
    content = List(Text("\nTransformerQEC adapts the transformer architecture to the structured prediction \ntask of syndrome decoding. The key innovation is a custom attention mechanism \nthat respects the locality structure of the surface code.\n\nThe architecture consists of:\n1. **Syndrome Embedding Layer**: Maps binary syndrome vectors to dense embeddings\n2. **Position Encoding**: Encodes the 2D structure of the surface code lattice\n3. **Transformer Blocks**: Self-attention layers with locality-aware masking\n4. **Prediction Head**: Classifies into error equivalence classes\n"))
)

define section_5_sub1 = Section(
    level = 2,
    title = "Training Methodology",
    label = "sec:training",
    content = List(Text("\nTraining neural decoders requires careful attention to the data distribution \nand loss function. We use a curriculum learning approach that gradually \nincreases error rates during training.\n\nThe training objective combines cross-entropy loss with a custom symmetry loss \nthat encourages the decoder to respect code symmetries:\n"))
)

define section_5_sub2 = Section(
    level = 2,
    title = "Benchmark Results",
    label = "sec:benchmark",
    content = List(Text("\nWe benchmark TransformerQEC against state-of-the-art decoders on the surface \ncode under depolarizing noise. Our decoder achieves the highest accuracy \nacross all code distances and error rates tested.\n"))
)

define section_6 = Section(
    level = 1,
    title = "AdaptiveQEC: Reinforcement Learning for Adaptive Decoding",
    label = "ch:adaptive",
    content = List(Text("\nReal quantum devices exhibit time-varying noise due to environmental \nfluctuations, calibration drift, and other factors. This chapter presents \nAdaptiveQEC, a reinforcement learning approach that continuously adapts \nthe decoder to changing noise conditions.\n"), SectionRef("section_6_sub0"), EqRef("reward"), SectionRef("section_6_sub1"))
)

define section_6_sub0 = Section(
    level = 2,
    title = "Reinforcement Learning Formulation",
    label = "sec:rl",
    content = List(Text("\nWe formulate adaptive decoding as a contextual bandit problem. The context \nincludes recent syndrome history and environmental measurements, while the \naction is the decoding strategy selection.\n\nThe reward signal is derived from logical measurement outcomes, providing \ndirect feedback on decoding quality. We use a Thompson sampling approach \nfor exploration-exploitation tradeoff.\n"))
)

define section_6_sub1 = Section(
    level = 2,
    title = "Results on Time-Varying Noise",
    label = "sec:adaptive_results",
    content = List(Text("\nWe evaluate AdaptiveQEC on simulated noise that varies over time, mimicking \nrealistic device behavior. The adaptive decoder significantly outperforms \nstatic decoders that are trained on fixed noise models.\n"))
)

define section_7 = Section(
    level = 1,
    title = "NeuralVQE: Error Mitigation for Variational Algorithms",
    label = "ch:vqe",
    content = List(Text("\nVariational quantum algorithms are a promising near-term application of \nquantum computers, but are severely limited by noise. This chapter presents \nNeuralVQE, which integrates neural error mitigation with variational \nquantum eigensolvers for chemistry simulations.\n"), SectionRef("section_7_sub0"), EqRef("vqe_objective"), Text("\nThe challenge is that noise corrupts the energy estimates, leading to \nsystematic biases that prevent finding the true ground state.\n"), SectionRef("section_7_sub1"), EqRef("mitigation"), SectionRef("section_7_sub2"))
)

define section_7_sub0 = Section(
    level = 2,
    title = "Variational Quantum Eigensolver",
    label = "sec:vqe_theory",
    content = List(Text("\nThe variational quantum eigensolver (VQE) estimates ground state energies \nby minimizing the expectation value of a Hamiltonian with respect to a \nparameterized quantum circuit:\n"))
)

define section_7_sub1 = Section(
    level = 2,
    title = "Neural Error Mitigation",
    label = "sec:mitigation",
    content = List(Text("\nNeuralVQE learns a correction function that maps noisy expectation values \nto error-mitigated estimates. The key insight is that the noise-induced \nbias has a predictable structure that can be learned from calibration data.\n"))
)

define section_7_sub2 = Section(
    level = 2,
    title = "Chemistry Applications",
    label = "sec:chemistry",
    content = List(Text("\nWe demonstrate NeuralVQE on molecular ground state energy calculations for \nmolecules relevant to catalysis and drug discovery.\n"))
)

define section_8 = Section(
    level = 1,
    title = "Experimental Validation",
    label = "ch:experiments",
    content = List(Text("\nThis chapter presents experimental validation of our neural quantum error \ncorrection methods on real quantum hardware. We conducted experiments on \nIBM Quantum and Google Quantum AI processors.\n"), SectionRef("section_8_sub0"), SectionRef("section_8_sub1"))
)

define section_8_sub0 = Section(
    level = 2,
    title = "IBM Quantum Experiments",
    label = "sec:ibm",
    content = List(Text("\nWe implemented TransformerQEC on IBM's 127-qubit Eagle processor, using a \ndistance-3 surface code patch. The neural decoder was trained on simulated \ndata calibrated to the device noise model, then deployed for real-time \ndecoding.\n"))
)

define section_8_sub1 = Section(
    level = 2,
    title = "Google Quantum AI Experiments",
    label = "sec:google",
    content = List(Text("\nOn Google's Sycamore processor, we implemented AdaptiveQEC to handle the \ntime-varying noise characteristic of superconducting systems. The adaptive \ndecoder significantly outperformed static decoders over extended operation.\n"))
)

define section_9 = Section(
    level = 1,
    title = "Conclusion",
    label = "ch:conclusion",
    content = List(Text("\nThis dissertation has presented neural network approaches to quantum error \ncorrection that advance the state of the art in decoder performance, \nadaptability, and practical applicability. Our work demonstrates that \nmachine learning is a powerful tool for addressing the central challenge \nof quantum computing.\n"), SectionRef("section_9_sub0"), SectionRef("section_9_sub1"), SectionRef("section_9_sub2"))
)

define section_9_sub0 = Section(
    level = 2,
    title = "Summary of Contributions",
    label = "sec:summary",
    content = List(Text("\nWe have made theoretical, algorithmic, and experimental contributions:\n\n1. **Theoretical**: We proved that neural networks can achieve maximum \n   likelihood decoding for any stabilizer code, establishing the foundation \n   for neural quantum error correction.\n\n2. **Algorithmic**: We developed TransformerQEC, AdaptiveQEC, and NeuralVQE, \n   each addressing different aspects of the error correction challenge.\n\n3. **Experimental**: We validated our methods on real quantum hardware, \n   demonstrating practical improvements in logical error rates.\n\nThese contributions represent significant progress toward the goal of \nfault-tolerant quantum computation.\n"))
)

define section_9_sub1 = Section(
    level = 2,
    title = "Future Directions",
    label = "sec:future",
    content = List(Text("\nSeveral promising directions emerge from this work:\n\n**Scaling to Larger Codes**: Extending our methods to distance-17 and \nbeyond will require architectural innovations to handle the increased \ncomplexity while maintaining real-time performance.\n\n**Hardware Integration**: Closer integration with quantum control systems \ncould enable even lower-latency decoding, potentially moving some \ncomputation to FPGAs or ASICs.\n\n**Beyond Stabilizer Codes**: Exploring neural decoders for non-stabilizer \ncodes such as bosonic codes could open new possibilities for \nerror-corrected quantum computing.\n\n**Hybrid Algorithms**: Combining neural error mitigation with fault-tolerant \ncomputing could enable practical quantum advantage sooner than either \napproach alone.\n"))
)

define section_9_sub2 = Section(
    level = 2,
    title = "Broader Impact",
    label = "sec:impact",
    content = List(Text("\nThe development of practical quantum error correction has implications \nbeyond the immediate technical contributions:\n\n**Timeline to Fault Tolerance**: Our 40% reduction in physical qubit \noverhead could accelerate the timeline to useful fault-tolerant quantum \ncomputing by several years.\n\n**Accessibility**: Open-source release of our implementations enables \nresearchers and practitioners worldwide to build on this work.\n\n**Interdisciplinary Connections**: This work demonstrates the power of \ncombining quantum physics with modern machine learning, pointing toward \na productive synthesis of these fields.\n\nWe are optimistic that continued progress in neural quantum error \ncorrection will help realize the transformative potential of quantum \ncomputing within the coming decade.\n"))
)

define section_10 = Section(
    level = 1,
    title = "Appendix A: Implementation Details",
    label = "app:impl",
    content = List(Text("\nThis appendix provides implementation details for reproducing our results. \nAll code is available at https://github.com/achen-umich/neural-qec.\n\n**Software Dependencies:**\n- Python 3.9+\n- PyTorch 2.0+\n- Qiskit 0.45+\n- Cirq 1.0+\n- Stim 1.10+\n\n**Hardware Requirements:**\n- Training: NVIDIA A100 GPU (40GB)\n- Inference: CPU sufficient for real-time operation\n- Quantum: Access to IBM/Google quantum processors via cloud APIs\n\n**Training Procedure:**\n1. Generate training data using Stim for fast Clifford simulation\n2. Train TransformerQEC for 100 epochs with learning rate 1e-4\n3. Fine-tune on device-specific noise model\n4. Validate on held-out test set before deployment\n"))
)

define section_11 = Section(
    level = 1,
    title = "Appendix B: Mathematical Proofs",
    label = "app:proofs",
    content = List(Text("\nThis appendix contains detailed proofs of the main theoretical results.\n\n**Proof of Theorem 3.1 (Universal Approximation for Decoders):**\n\nWe proceed in three stages...\n\n[Detailed mathematical proof spanning several pages]\n\n**Proof of Theorem 3.2 (Sample Complexity Bound):**\n\nUsing standard PAC learning theory combined with the structure of \nstabilizer codes...\n\n[Detailed mathematical proof]\n"))
)

// ----------------------------------------------------------------------------
// Document Assembly
// ----------------------------------------------------------------------------

define document = KleisDoc(
    metadata = doc_metadata,
    equations = List(error_rate, pauli_group, stabilizer_condition, surface_threshold, ml_decoding, universal_approx, sample_complexity, training_loss, reward, vqe_objective, mitigation),
    figures = List(performance_plot),
    sections = List(section_0, section_1, section_2, section_3, section_4, section_5, section_6, section_7, section_8, section_9, section_10, section_11)
)
